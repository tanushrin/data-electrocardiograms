{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Electrocardiograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Electrocardiograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Import the [`electrocardiograms.csv`](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_dataset.csv) dataset and display its first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_17</th>\n",
       "      <th>x_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>x_20</th>\n",
       "      <th>x_21</th>\n",
       "      <th>x_22</th>\n",
       "      <th>x_23</th>\n",
       "      <th>x_24</th>\n",
       "      <th>x_25</th>\n",
       "      <th>x_26</th>\n",
       "      <th>x_27</th>\n",
       "      <th>x_28</th>\n",
       "      <th>x_29</th>\n",
       "      <th>x_30</th>\n",
       "      <th>x_31</th>\n",
       "      <th>x_32</th>\n",
       "      <th>x_33</th>\n",
       "      <th>x_34</th>\n",
       "      <th>x_35</th>\n",
       "      <th>x_36</th>\n",
       "      <th>x_37</th>\n",
       "      <th>x_38</th>\n",
       "      <th>x_39</th>\n",
       "      <th>x_40</th>\n",
       "      <th>x_41</th>\n",
       "      <th>x_42</th>\n",
       "      <th>x_43</th>\n",
       "      <th>x_44</th>\n",
       "      <th>x_45</th>\n",
       "      <th>x_46</th>\n",
       "      <th>x_47</th>\n",
       "      <th>x_48</th>\n",
       "      <th>x_49</th>\n",
       "      <th>x_50</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_56</th>\n",
       "      <th>x_57</th>\n",
       "      <th>x_58</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_60</th>\n",
       "      <th>x_61</th>\n",
       "      <th>x_62</th>\n",
       "      <th>x_63</th>\n",
       "      <th>x_64</th>\n",
       "      <th>x_65</th>\n",
       "      <th>x_66</th>\n",
       "      <th>x_67</th>\n",
       "      <th>x_68</th>\n",
       "      <th>x_69</th>\n",
       "      <th>x_70</th>\n",
       "      <th>x_71</th>\n",
       "      <th>x_72</th>\n",
       "      <th>x_73</th>\n",
       "      <th>x_74</th>\n",
       "      <th>x_75</th>\n",
       "      <th>x_76</th>\n",
       "      <th>x_77</th>\n",
       "      <th>x_78</th>\n",
       "      <th>x_79</th>\n",
       "      <th>x_80</th>\n",
       "      <th>x_81</th>\n",
       "      <th>x_82</th>\n",
       "      <th>x_83</th>\n",
       "      <th>x_84</th>\n",
       "      <th>x_85</th>\n",
       "      <th>x_86</th>\n",
       "      <th>x_87</th>\n",
       "      <th>x_88</th>\n",
       "      <th>x_89</th>\n",
       "      <th>x_90</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_100</th>\n",
       "      <th>x_101</th>\n",
       "      <th>x_102</th>\n",
       "      <th>x_103</th>\n",
       "      <th>x_104</th>\n",
       "      <th>x_105</th>\n",
       "      <th>x_106</th>\n",
       "      <th>x_107</th>\n",
       "      <th>x_108</th>\n",
       "      <th>x_109</th>\n",
       "      <th>x_110</th>\n",
       "      <th>x_111</th>\n",
       "      <th>x_112</th>\n",
       "      <th>x_113</th>\n",
       "      <th>x_114</th>\n",
       "      <th>x_115</th>\n",
       "      <th>x_116</th>\n",
       "      <th>x_117</th>\n",
       "      <th>x_118</th>\n",
       "      <th>x_119</th>\n",
       "      <th>x_120</th>\n",
       "      <th>x_121</th>\n",
       "      <th>x_122</th>\n",
       "      <th>x_123</th>\n",
       "      <th>x_124</th>\n",
       "      <th>x_125</th>\n",
       "      <th>x_126</th>\n",
       "      <th>x_127</th>\n",
       "      <th>x_128</th>\n",
       "      <th>x_129</th>\n",
       "      <th>x_130</th>\n",
       "      <th>x_131</th>\n",
       "      <th>x_132</th>\n",
       "      <th>x_133</th>\n",
       "      <th>x_134</th>\n",
       "      <th>x_135</th>\n",
       "      <th>x_136</th>\n",
       "      <th>x_137</th>\n",
       "      <th>x_138</th>\n",
       "      <th>x_139</th>\n",
       "      <th>x_140</th>\n",
       "      <th>x_141</th>\n",
       "      <th>x_142</th>\n",
       "      <th>x_143</th>\n",
       "      <th>x_144</th>\n",
       "      <th>x_145</th>\n",
       "      <th>x_146</th>\n",
       "      <th>x_147</th>\n",
       "      <th>x_148</th>\n",
       "      <th>x_149</th>\n",
       "      <th>x_150</th>\n",
       "      <th>x_151</th>\n",
       "      <th>x_152</th>\n",
       "      <th>x_153</th>\n",
       "      <th>x_154</th>\n",
       "      <th>x_155</th>\n",
       "      <th>x_156</th>\n",
       "      <th>x_157</th>\n",
       "      <th>x_158</th>\n",
       "      <th>x_159</th>\n",
       "      <th>x_160</th>\n",
       "      <th>x_161</th>\n",
       "      <th>x_162</th>\n",
       "      <th>x_163</th>\n",
       "      <th>x_164</th>\n",
       "      <th>x_165</th>\n",
       "      <th>x_166</th>\n",
       "      <th>x_167</th>\n",
       "      <th>x_168</th>\n",
       "      <th>x_169</th>\n",
       "      <th>x_170</th>\n",
       "      <th>x_171</th>\n",
       "      <th>x_172</th>\n",
       "      <th>x_173</th>\n",
       "      <th>x_174</th>\n",
       "      <th>x_175</th>\n",
       "      <th>x_176</th>\n",
       "      <th>x_177</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.322097</td>\n",
       "      <td>0.363296</td>\n",
       "      <td>0.413858</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.485019</td>\n",
       "      <td>0.511236</td>\n",
       "      <td>0.520599</td>\n",
       "      <td>0.548689</td>\n",
       "      <td>0.599251</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.664794</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.852060</td>\n",
       "      <td>0.897004</td>\n",
       "      <td>0.953184</td>\n",
       "      <td>0.970037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.823970</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.602996</td>\n",
       "      <td>0.576779</td>\n",
       "      <td>0.597378</td>\n",
       "      <td>0.670412</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.513109</td>\n",
       "      <td>0.423221</td>\n",
       "      <td>0.277154</td>\n",
       "      <td>0.119850</td>\n",
       "      <td>0.082397</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.039326</td>\n",
       "      <td>0.054307</td>\n",
       "      <td>0.063670</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.303371</td>\n",
       "      <td>0.355805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.364286</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>0.308929</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>0.291071</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.283929</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.255357</td>\n",
       "      <td>0.264286</td>\n",
       "      <td>0.260714</td>\n",
       "      <td>0.251786</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>0.226786</td>\n",
       "      <td>0.217857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.173214</td>\n",
       "      <td>0.164286</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>0.141071</td>\n",
       "      <td>0.144643</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>0.167857</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.223214</td>\n",
       "      <td>0.251786</td>\n",
       "      <td>0.255357</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.310714</td>\n",
       "      <td>0.323214</td>\n",
       "      <td>0.323214</td>\n",
       "      <td>0.326786</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.341071</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.358929</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.308929</td>\n",
       "      <td>0.360714</td>\n",
       "      <td>0.455357</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.366071</td>\n",
       "      <td>0.205357</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.048214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.101786</td>\n",
       "      <td>0.146429</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.246429</td>\n",
       "      <td>0.301786</td>\n",
       "      <td>0.351786</td>\n",
       "      <td>0.382143</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.398214</td>\n",
       "      <td>0.407143</td>\n",
       "      <td>0.407143</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951276</td>\n",
       "      <td>0.903712</td>\n",
       "      <td>0.917633</td>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.803944</td>\n",
       "      <td>0.656613</td>\n",
       "      <td>0.421114</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.269142</td>\n",
       "      <td>0.244780</td>\n",
       "      <td>0.230858</td>\n",
       "      <td>0.216937</td>\n",
       "      <td>0.209977</td>\n",
       "      <td>0.206497</td>\n",
       "      <td>0.193735</td>\n",
       "      <td>0.187935</td>\n",
       "      <td>0.179814</td>\n",
       "      <td>0.177494</td>\n",
       "      <td>0.160093</td>\n",
       "      <td>0.142691</td>\n",
       "      <td>0.133411</td>\n",
       "      <td>0.132251</td>\n",
       "      <td>0.121810</td>\n",
       "      <td>0.107889</td>\n",
       "      <td>0.106729</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>0.096288</td>\n",
       "      <td>0.075406</td>\n",
       "      <td>0.066125</td>\n",
       "      <td>0.048724</td>\n",
       "      <td>0.022042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.024362</td>\n",
       "      <td>0.046404</td>\n",
       "      <td>0.067285</td>\n",
       "      <td>0.112529</td>\n",
       "      <td>0.155452</td>\n",
       "      <td>0.196056</td>\n",
       "      <td>0.220418</td>\n",
       "      <td>0.241299</td>\n",
       "      <td>0.256380</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.262181</td>\n",
       "      <td>0.257541</td>\n",
       "      <td>0.259861</td>\n",
       "      <td>0.261021</td>\n",
       "      <td>0.269142</td>\n",
       "      <td>0.265661</td>\n",
       "      <td>0.263341</td>\n",
       "      <td>0.263341</td>\n",
       "      <td>0.271462</td>\n",
       "      <td>0.270302</td>\n",
       "      <td>0.270302</td>\n",
       "      <td>0.273782</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.271462</td>\n",
       "      <td>0.273782</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>0.273782</td>\n",
       "      <td>0.277262</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.285383</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.280742</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.287703</td>\n",
       "      <td>0.286543</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.287703</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.299304</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.299304</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.298144</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.306264</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.309745</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.302784</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.299304</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.305104</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.313225</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.309745</td>\n",
       "      <td>0.309745</td>\n",
       "      <td>0.317865</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.317865</td>\n",
       "      <td>0.319026</td>\n",
       "      <td>0.328306</td>\n",
       "      <td>0.341067</td>\n",
       "      <td>0.352668</td>\n",
       "      <td>0.37007</td>\n",
       "      <td>0.390951</td>\n",
       "      <td>0.385151</td>\n",
       "      <td>0.387471</td>\n",
       "      <td>0.37587</td>\n",
       "      <td>0.338747</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.312065</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.308585</td>\n",
       "      <td>0.307425</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.283063</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.402552</td>\n",
       "      <td>0.62181</td>\n",
       "      <td>0.790023</td>\n",
       "      <td>0.75174</td>\n",
       "      <td>0.468677</td>\n",
       "      <td>0.267981</td>\n",
       "      <td>0.349188</td>\n",
       "      <td>0.356148</td>\n",
       "      <td>0.313225</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.305104</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.302784</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.100932</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.270186</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.319876</td>\n",
       "      <td>0.316770</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.319876</td>\n",
       "      <td>0.316770</td>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.322981</td>\n",
       "      <td>0.330745</td>\n",
       "      <td>0.343168</td>\n",
       "      <td>0.355590</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.394410</td>\n",
       "      <td>0.406832</td>\n",
       "      <td>0.406832</td>\n",
       "      <td>0.411491</td>\n",
       "      <td>0.405280</td>\n",
       "      <td>0.395963</td>\n",
       "      <td>0.377329</td>\n",
       "      <td>0.377329</td>\n",
       "      <td>0.378882</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.371118</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.378882</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.371118</td>\n",
       "      <td>0.375776</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.374224</td>\n",
       "      <td>0.371118</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.389752</td>\n",
       "      <td>0.394410</td>\n",
       "      <td>0.408385</td>\n",
       "      <td>0.416149</td>\n",
       "      <td>0.439441</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.470497</td>\n",
       "      <td>0.451863</td>\n",
       "      <td>0.459627</td>\n",
       "      <td>0.453416</td>\n",
       "      <td>0.427019</td>\n",
       "      <td>0.399068</td>\n",
       "      <td>0.394410</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.354037</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.388199</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.614907</td>\n",
       "      <td>0.406832</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.349379</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.298137</td>\n",
       "      <td>0.301242</td>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.298137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619217</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.145907</td>\n",
       "      <td>0.192171</td>\n",
       "      <td>0.222420</td>\n",
       "      <td>0.259786</td>\n",
       "      <td>0.279359</td>\n",
       "      <td>0.282918</td>\n",
       "      <td>0.279359</td>\n",
       "      <td>0.275801</td>\n",
       "      <td>0.281139</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.286477</td>\n",
       "      <td>0.281139</td>\n",
       "      <td>0.279359</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.297153</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.334520</td>\n",
       "      <td>0.357651</td>\n",
       "      <td>0.380783</td>\n",
       "      <td>0.405694</td>\n",
       "      <td>0.435943</td>\n",
       "      <td>0.464413</td>\n",
       "      <td>0.476868</td>\n",
       "      <td>0.491103</td>\n",
       "      <td>0.508897</td>\n",
       "      <td>0.501779</td>\n",
       "      <td>0.496441</td>\n",
       "      <td>0.483986</td>\n",
       "      <td>0.471530</td>\n",
       "      <td>0.457295</td>\n",
       "      <td>0.430605</td>\n",
       "      <td>0.416370</td>\n",
       "      <td>0.407473</td>\n",
       "      <td>0.386121</td>\n",
       "      <td>0.359431</td>\n",
       "      <td>0.350534</td>\n",
       "      <td>0.354093</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.330961</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.330961</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.314947</td>\n",
       "      <td>0.322064</td>\n",
       "      <td>0.318505</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.311388</td>\n",
       "      <td>0.316726</td>\n",
       "      <td>0.311388</td>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.298932</td>\n",
       "      <td>0.307829</td>\n",
       "      <td>0.304270</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.298932</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.290036</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.288256</td>\n",
       "      <td>0.286477</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.297153</td>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.300712</td>\n",
       "      <td>0.309609</td>\n",
       "      <td>0.323843</td>\n",
       "      <td>0.330961</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.320285</td>\n",
       "      <td>0.314947</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.281139</td>\n",
       "      <td>0.274021</td>\n",
       "      <td>0.266904</td>\n",
       "      <td>0.263345</td>\n",
       "      <td>0.261566</td>\n",
       "      <td>0.263345</td>\n",
       "      <td>0.272242</td>\n",
       "      <td>0.277580</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>0.354093</td>\n",
       "      <td>0.471530</td>\n",
       "      <td>0.658363</td>\n",
       "      <td>0.850534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976868</td>\n",
       "      <td>0.542705</td>\n",
       "      <td>0.193950</td>\n",
       "      <td>0.185053</td>\n",
       "      <td>0.218861</td>\n",
       "      <td>0.224199</td>\n",
       "      <td>0.201068</td>\n",
       "      <td>0.204626</td>\n",
       "      <td>0.209964</td>\n",
       "      <td>0.201068</td>\n",
       "      <td>0.197509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2       x_3       x_4       x_5       x_6       x_7  \\\n",
       "0  0.000000  0.041199  0.112360  0.146067  0.202247  0.322097  0.363296   \n",
       "1  1.000000  0.901786  0.760714  0.610714  0.466071  0.385714  0.364286   \n",
       "2  0.994200  1.000000  0.951276  0.903712  0.917633  0.900232  0.803944   \n",
       "3  0.984472  0.962733  0.663043  0.211180  0.000000  0.032609  0.100932   \n",
       "4  0.619217  0.489324  0.327402  0.110320  0.000000  0.060498  0.108541   \n",
       "\n",
       "        x_8       x_9      x_10      x_11      x_12      x_13      x_14  \\\n",
       "0  0.413858  0.426966  0.485019  0.511236  0.520599  0.548689  0.599251   \n",
       "1  0.346429  0.314286  0.305357  0.308929  0.305357  0.291071  0.285714   \n",
       "2  0.656613  0.421114  0.288863  0.290023  0.269142  0.244780  0.230858   \n",
       "3  0.177019  0.270186  0.313665  0.307453  0.312112  0.312112  0.313665   \n",
       "4  0.108541  0.145907  0.192171  0.222420  0.259786  0.279359  0.282918   \n",
       "\n",
       "       x_15      x_16      x_17      x_18      x_19      x_20      x_21  \\\n",
       "0  0.606742  0.640449  0.664794  0.730337  0.780899  0.852060  0.897004   \n",
       "1  0.283929  0.271429  0.255357  0.264286  0.260714  0.251786  0.241071   \n",
       "2  0.216937  0.209977  0.206497  0.193735  0.187935  0.179814  0.177494   \n",
       "3  0.315217  0.319876  0.316770  0.312112  0.313665  0.319876  0.316770   \n",
       "4  0.279359  0.275801  0.281139  0.288256  0.286477  0.281139  0.279359   \n",
       "\n",
       "       x_22      x_23      x_24      x_25      x_26      x_27      x_28  \\\n",
       "0  0.953184  0.970037  1.000000  0.992509  0.985019  0.943820  0.898876   \n",
       "1  0.226786  0.217857  0.200000  0.173214  0.164286  0.160714  0.155357   \n",
       "2  0.160093  0.142691  0.133411  0.132251  0.121810  0.107889  0.106729   \n",
       "3  0.307453  0.313665  0.315217  0.315217  0.322981  0.330745  0.343168   \n",
       "4  0.290036  0.291815  0.297153  0.313167  0.334520  0.357651  0.380783   \n",
       "\n",
       "       x_29      x_30      x_31      x_32      x_33      x_34      x_35  \\\n",
       "0  0.823970  0.752809  0.711610  0.666667  0.602996  0.576779  0.597378   \n",
       "1  0.141071  0.144643  0.155357  0.167857  0.175000  0.192857  0.223214   \n",
       "2  0.113689  0.096288  0.075406  0.066125  0.048724  0.022042  0.000000   \n",
       "3  0.355590  0.366460  0.380435  0.394410  0.406832  0.406832  0.411491   \n",
       "4  0.405694  0.435943  0.464413  0.476868  0.491103  0.508897  0.501779   \n",
       "\n",
       "       x_36      x_37      x_38      x_39      x_40      x_41      x_42  \\\n",
       "0  0.670412  0.595506  0.513109  0.423221  0.277154  0.119850  0.082397   \n",
       "1  0.251786  0.255357  0.276786  0.310714  0.323214  0.323214  0.326786   \n",
       "2  0.002320  0.024362  0.046404  0.067285  0.112529  0.155452  0.196056   \n",
       "3  0.405280  0.395963  0.377329  0.377329  0.378882  0.369565  0.363354   \n",
       "4  0.496441  0.483986  0.471530  0.457295  0.430605  0.416370  0.407473   \n",
       "\n",
       "       x_43      x_44      x_45      x_46      x_47      x_48      x_49  \\\n",
       "0  0.022472  0.039326  0.054307  0.063670  0.198502  0.303371  0.355805   \n",
       "1  0.342857  0.346429  0.339286  0.342857  0.348214  0.346429  0.335714   \n",
       "2  0.220418  0.241299  0.256380  0.257541  0.252900  0.257541  0.262181   \n",
       "3  0.366460  0.366460  0.361801  0.357143  0.366460  0.369565  0.363354   \n",
       "4  0.386121  0.359431  0.350534  0.354093  0.341637  0.330961  0.327402   \n",
       "\n",
       "       x_50      x_51      x_52      x_53      x_54      x_55      x_56  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.335714  0.339286  0.341071  0.342857  0.357143  0.358929  0.328571   \n",
       "2  0.257541  0.259861  0.261021  0.269142  0.265661  0.263341  0.263341   \n",
       "3  0.361801  0.366460  0.372671  0.371118  0.369565  0.369565  0.378882   \n",
       "4  0.330961  0.327402  0.313167  0.314947  0.322064  0.318505  0.313167   \n",
       "\n",
       "       x_57      x_58      x_59      x_60      x_61      x_62      x_63  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.308929  0.360714  0.455357  0.457143  0.366071  0.205357  0.114286   \n",
       "2  0.271462  0.270302  0.270302  0.273782  0.278422  0.278422  0.271462   \n",
       "3  0.366460  0.357143  0.371118  0.375776  0.372671  0.364907  0.369565   \n",
       "4  0.311388  0.316726  0.311388  0.302491  0.298932  0.307829  0.304270   \n",
       "\n",
       "       x_64      x_65      x_66      x_67      x_68      x_69      x_70  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.048214  0.000000  0.041071  0.101786  0.146429  0.187500  0.246429   \n",
       "2  0.273782  0.278422  0.279582  0.273782  0.277262  0.279582  0.279582   \n",
       "3  0.374224  0.371118  0.372671  0.380435  0.389752  0.394410  0.408385   \n",
       "4  0.295374  0.290036  0.298932  0.291815  0.290036  0.290036  0.295374   \n",
       "\n",
       "       x_71      x_72      x_73      x_74      x_75      x_76      x_77  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.301786  0.351786  0.382143  0.387500  0.398214  0.407143  0.407143   \n",
       "2  0.278422  0.278422  0.285383  0.283063  0.280742  0.283063  0.287703   \n",
       "3  0.416149  0.439441  0.456522  0.470497  0.451863  0.459627  0.453416   \n",
       "4  0.288256  0.290036  0.288256  0.288256  0.288256  0.286477  0.291815   \n",
       "\n",
       "       x_78      x_79      x_80      x_81      x_82      x_83      x_84  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.410714  0.421429  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.286543  0.283063  0.287703  0.291183  0.293503  0.290023  0.291183   \n",
       "3  0.427019  0.399068  0.394410  0.369565  0.354037  0.363354  0.364907   \n",
       "4  0.297153  0.302491  0.300712  0.309609  0.323843  0.330961  0.327402   \n",
       "\n",
       "       x_85      x_86      x_87      x_88      x_89      x_90      x_91  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.296984  0.294664  0.290023  0.290023  0.295824  0.291183  0.293503   \n",
       "3  0.366460  0.364907  0.388199  0.535714  0.734472  0.911491  1.000000   \n",
       "4  0.320285  0.314947  0.295374  0.281139  0.274021  0.266904  0.263345   \n",
       "\n",
       "       x_92      x_93      x_94      x_95      x_96      x_97      x_98  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.293503  0.300464  0.301624  0.296984  0.294664  0.300464  0.294664   \n",
       "3  0.919255  0.614907  0.406832  0.372671  0.349379  0.315217  0.304348   \n",
       "4  0.261566  0.263345  0.272242  0.277580  0.295374  0.354093  0.471530   \n",
       "\n",
       "       x_99     x_100     x_101     x_102     x_103     x_104     x_105  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.293503  0.299304  0.303944  0.300464  0.294664  0.299304  0.307425   \n",
       "3  0.313665  0.312112  0.304348  0.298137  0.301242  0.307453  0.298137   \n",
       "4  0.658363  0.850534  1.000000  0.976868  0.542705  0.193950  0.185053   \n",
       "\n",
       "      x_106     x_107     x_108     x_109     x_110     x_111     x_112  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.301624  0.300464  0.293503  0.303944  0.303944  0.298144  0.296984   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.218861  0.224199  0.201068  0.204626  0.209964  0.201068  0.197509   \n",
       "\n",
       "      x_113     x_114     x_115     x_116     x_117     x_118     x_119  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.303944  0.306264  0.300464  0.301624  0.309745  0.312065  0.307425   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_120     x_121     x_122     x_123     x_124     x_125     x_126  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.302784  0.310905  0.308585  0.299304  0.301624  0.307425  0.310905   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_127     x_128     x_129     x_130     x_131     x_132     x_133  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.305104  0.308585  0.313225  0.310905  0.309745  0.309745  0.317865   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_134     x_135     x_136     x_137     x_138     x_139     x_140  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.315545  0.310905  0.312065  0.317865  0.319026  0.328306  0.341067   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_141    x_142     x_143     x_144     x_145    x_146     x_147  \\\n",
       "0  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "1  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "2  0.352668  0.37007  0.390951  0.385151  0.387471  0.37587  0.338747   \n",
       "3  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "4  0.000000  0.00000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "\n",
       "      x_148     x_149     x_150     x_151     x_152     x_153     x_154  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.312065  0.308585  0.312065  0.307425  0.301624  0.308585  0.307425   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_155     x_156     x_157     x_158    x_159     x_160    x_161  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "2  0.300464  0.283063  0.301624  0.402552  0.62181  0.790023  0.75174   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000   \n",
       "\n",
       "      x_162     x_163     x_164     x_165     x_166     x_167     x_168  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.468677  0.267981  0.349188  0.356148  0.313225  0.295824  0.305104   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_169     x_170     x_171     x_172     x_173     x_174     x_175  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.301624  0.302784  0.294664  0.295824  0.300464  0.296984  0.293503   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      x_176     x_177     x_178     x_179     x_180     x_181  x_182  x_183  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "2  0.290023  0.296984  0.300464  0.294664  0.295824  0.301624    0.0    0.0   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "\n",
       "   x_184  x_185  x_186  x_187  target  \n",
       "0    0.0    0.0    0.0    0.0       1  \n",
       "1    0.0    0.0    0.0    0.0       1  \n",
       "2    0.0    0.0    0.0    0.0       1  \n",
       "3    0.0    0.0    0.0    0.0       1  \n",
       "4    0.0    0.0    0.0    0.0       1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "data = pd.read_csv('data/electrocardiograms.csv')\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19565 entries, 0 to 19564\n",
      "Columns: 188 entries, x_1 to target\n",
      "dtypes: float64(187), int64(1)\n",
      "memory usage: 28.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’“ Each observation of the dataset is a sequence of measured heartbeats, taken from a patient's electrocardiogram (ECG).\n",
    "\n",
    "ðŸŽ¯ The target is binary and defines whether the heartbeat shows:\n",
    "* a risk of cardiovascular disease ðŸ”´ (1)\n",
    "* or not ðŸŸ¢ (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question** â“\n",
    "\n",
    "Plot an observation of each target class to get a visual idea of what the numbers represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot counts of each target\n",
    "sns.countplot(x='target', data=data)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Questions** â“\n",
    "\n",
    "* How many observations of at-risk heartbeats are there? Save your answer as `at_risk_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients at risk: 1448\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "at_risk_count = data[data['target'] == 1].shape[0]\n",
    "print(f'Number of patients at risk: {at_risk_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many observations of healthy heartbeats are there? Save your answer as `healthy_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of healthy patients: 18117\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "healthy_count = data[data['target'] == 0].shape[0]\n",
    "print(f'Number of healthy patients: {healthy_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘©ðŸ»â€ðŸ« In certain cases, the class balance is representative of the true class distribution. This is the case here: the vast majority of people actually have healthy hearts. In such case, we preserve the class distribution to train the model based on reality, and adapt our modeling approach accordingly.\n",
    "\n",
    "[Centers for Disease Control and Prevention - Heart Disease Facts](https://www.cdc.gov/heartdisease/facts.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/tanushrinayak/.pyenv/versions/3.10.6/envs/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/tanushrinayak/code/tanushrin/05-ML/03-Performance-metrics/data-electrocardiograms/tests\n",
      "plugins: asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_class_balance.py::TestClass_balance::test_at_risk_count \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
      "test_class_balance.py::TestClass_balance::test_healthy_count \u001b[32mPASSED\u001b[0m\u001b[32m      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/class_balance.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed class_balance step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('class_balance',\n",
    "                         healthy = healthy_count,\n",
    "                         at_risk = at_risk_count)\n",
    "result.write()\n",
    "print(result.check())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (3) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ¯ Your task is to **flag heartbeats that are at risk of cardiovascular diseases.**\n",
    "\n",
    "ðŸ‘‡ Let's start by investigating the performance of a `LogisticRegression` on that task. Use a ***cross-validation to evaluate the model*** on the following metrics:\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "- F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9391771019677997\n",
      "Precision: 0.6867386740061804\n",
      "Recall: 0.3300942608280635\n",
      "F1: 0.44482198050033483\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Logisitic regression model with cross validation to find Accuracy, Precision, Recall, and F1 score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = cross_validate(model, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "accuracy = scores['test_accuracy'].mean()\n",
    "precision = scores['test_precision'].mean()\n",
    "recall = scores['test_recall'].mean()\n",
    "f1 = scores['test_f1'].mean()\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Ratio of correct predictions)** â“ \n",
    "\n",
    "What is the ratio of correct predictions for this model ? Save your answer under variable name `correct_pred_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "correct_pred_ratio = accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Ability to flag at-risk patients)** â“ \n",
    "\n",
    "What percentage of at-risk heartbeats is the model able to flag? Save your answer under variable name `flag_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "flag_ratio = recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Ability to flag correctly)** â“ \n",
    "\n",
    "When the model signals an at-risk heartbeat, how often is it correct? Save your answer under variable name `correct_detection_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "correct_detection_ratio = precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Detecting as many at-risk patients as possible without too many false alarms)** â“ \n",
    "\n",
    "What is the model's ability to flag as many at-risk heartbeats as possible while limiting false alarms?  Save your answer under variable name `aggregated_metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "aggregated_metric = f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/tanushrinayak/.pyenv/versions/3.10.6/envs/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/tanushrinayak/code/tanushrin/05-ML/03-Performance-metrics/data-electrocardiograms/tests\n",
      "plugins: asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_accuracy \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_f1 \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_precision \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_recall \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/logistic_regression_evaluation.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed logistic_regression_evaluation step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('logistic_regression_evaluation',\n",
    "                         accuracy = correct_pred_ratio,\n",
    "                         recall = flag_ratio,\n",
    "                         precision = correct_detection_ratio,\n",
    "                         f1 = aggregated_metric)\n",
    "result.write()\n",
    "print(result.check())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â–¶ï¸ Run the following cell before moving on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should have noticed that the model was able to predict correctly in 94 cases out of 100. \n",
      "However, it was able to capture only 33.0 % of the at-risk patients\n",
      "Why ? Let's print a confusion matrix!\n"
     ]
    }
   ],
   "source": [
    "print(f\"You should have noticed that the model was able to predict correctly in {int(round(correct_pred_ratio,2)*100)} cases out of 100. \")\n",
    "\n",
    "print(f\"However, it was able to capture only {round(flag_ratio,2)*100} % of the at-risk patients\")\n",
    "\n",
    "print(\"Why ? Let's print a confusion matrix!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Using `ConfusionMatrixDisplay` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay)),  visualize the predictions breakdown of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Hints</summary>\n",
    "\n",
    "    \n",
    "1. [from_estimator](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_estimator)    \n",
    "2. [from_predictions](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions)\n",
    "    \n",
    "- Don't forget to to go back to the **Holdout method** to [`train-test-split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) your dataset and look at the confusion matrix on the test set.  \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3566   45]\n",
      " [ 206   96]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# ConfusionMatrixDisplay to plot a confusion matrix for the\n",
    "# logistic regression model using train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion matrix:\\n{cm}\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â„¹ï¸ The confusion matrix should show that the model is influenced by the class imbalance: it predicts the heartbeats to be healthy most of the time. Due to this behaviour, the model is often correct and has a **high accuracy**. However, this also causes it to miss out on many at-risk heartbeats: it has **bad recall**...\n",
    "\n",
    "ðŸ‘‰ This model is therefore poor at the task of **flagging at-risk observations**.\n",
    "\n",
    "â—ï¸ Don't be fooled by the accuracy and look at the metric that corresponds to your task! â—ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Classification Model Selection)** â“ \n",
    "\n",
    "Would a default KNN classifier perform better at the task of flagging at-risk observations?\n",
    "\n",
    "Save the you answer under `best_model` as \"KNN\" or \"LogisticRegression\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9854331714796831\n",
      "Precision: 0.9403030439629824\n",
      "Recall: 0.8577210356759336\n",
      "F1: 0.8970183275075831\n",
      "The best model is KNN\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Use KNN classifier with cross validation to find Accuracy, Precision, Recall, and F1 score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = cross_validate(model, X, y, scoring=scoring, cv=5)\n",
    "\n",
    "knn_accuracy = scores['test_accuracy'].mean()\n",
    "knn_precision = scores['test_precision'].mean()\n",
    "knn_recall = scores['test_recall'].mean()\n",
    "knn_f1 = scores['test_f1'].mean()\n",
    "\n",
    "print(f\"Accuracy: {knn_accuracy}\")\n",
    "print(f\"Precision: {knn_precision}\")\n",
    "print(f\"Recall: {knn_recall}\")\n",
    "print(f\"F1: {knn_f1}\")\n",
    "\n",
    "best_model = \"KNN\" if knn_f1 > f1 else \"LogisticRegression\"\n",
    "print(f\"The best model is {best_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’ª For this ECG dataset, the KNN Classifier should have a much higher recall than the LogisticRegression and therefore is better suited for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/tanushrinayak/.pyenv/versions/3.10.6/envs/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/tanushrinayak/code/tanushrin/05-ML/03-Performance-metrics/data-electrocardiograms/tests\n",
      "plugins: asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_best_model.py::TestBest_model::test_best_model \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/best_model.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed best_model step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('best_model',\n",
    "                         model = best_model)\n",
    "result.write()\n",
    "print(result.check())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected the KNN model thanks to its higherbest recall, let's have a look at the other classification performance metrics>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Classification Report)** â“\n",
    "\n",
    "Print out a [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) of the KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> ðŸ’¡ <i>Hint</i>  </summary>\n",
    "    \n",
    "* You will need to pass the predictions of the model to a `classification_report`.\n",
    "    \n",
    "* SkLearn's [`cross_val_predict`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) might help ðŸ˜‰\n",
    "</details>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3605\n",
      "           1       0.93      0.86      0.89       308\n",
      "\n",
      "    accuracy                           0.98      3913\n",
      "   macro avg       0.96      0.93      0.94      3913\n",
      "weighted avg       0.98      0.98      0.98      3913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Print a classification report for the KNN model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Reading the report)** â“\n",
    "\n",
    "\n",
    "Among the heartbeats predicted at-risk, what is the ratio of correct predictions ? \n",
    "\n",
    "In mathematical terms, can you read the ratio $ \\frac{TP}{TP + FP} $ in the report? What is the name of this classification metrics ? \n",
    "\n",
    "Save your answer as a float under `correct_at_risk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "correct_at_risk_predictions = 0.93\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/tanushrinayak/.pyenv/versions/3.10.6/envs/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/tanushrinayak/code/tanushrin/05-ML/03-Performance-metrics/data-electrocardiograms/tests\n",
      "plugins: asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_precision.py::TestPrecision::test_precision \u001b[32mPASSED\u001b[0m\u001b[32m                  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/precision.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed precision step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('precision',\n",
    "                         precision = correct_at_risk_predictions)\n",
    "result.write()\n",
    "print(result.check())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Question (Predicting)** â“\n",
    "\n",
    "A patient comes to you for a second opinion because  he was told that based on his heartbeats, this patient may be at-risk.  \n",
    "\n",
    "According to your optimal model, is he at-risk or not?  \n",
    "\n",
    "Save the prediction of your model under variable name `prediction` as \"at risk\" or \"healthy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_17</th>\n",
       "      <th>x_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>x_20</th>\n",
       "      <th>x_21</th>\n",
       "      <th>x_22</th>\n",
       "      <th>x_23</th>\n",
       "      <th>x_24</th>\n",
       "      <th>x_25</th>\n",
       "      <th>x_26</th>\n",
       "      <th>x_27</th>\n",
       "      <th>x_28</th>\n",
       "      <th>x_29</th>\n",
       "      <th>x_30</th>\n",
       "      <th>x_31</th>\n",
       "      <th>x_32</th>\n",
       "      <th>x_33</th>\n",
       "      <th>x_34</th>\n",
       "      <th>x_35</th>\n",
       "      <th>x_36</th>\n",
       "      <th>x_37</th>\n",
       "      <th>x_38</th>\n",
       "      <th>x_39</th>\n",
       "      <th>x_40</th>\n",
       "      <th>x_41</th>\n",
       "      <th>x_42</th>\n",
       "      <th>x_43</th>\n",
       "      <th>x_44</th>\n",
       "      <th>x_45</th>\n",
       "      <th>x_46</th>\n",
       "      <th>x_47</th>\n",
       "      <th>x_48</th>\n",
       "      <th>x_49</th>\n",
       "      <th>x_50</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_56</th>\n",
       "      <th>x_57</th>\n",
       "      <th>x_58</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_60</th>\n",
       "      <th>x_61</th>\n",
       "      <th>x_62</th>\n",
       "      <th>x_63</th>\n",
       "      <th>x_64</th>\n",
       "      <th>x_65</th>\n",
       "      <th>x_66</th>\n",
       "      <th>x_67</th>\n",
       "      <th>x_68</th>\n",
       "      <th>x_69</th>\n",
       "      <th>x_70</th>\n",
       "      <th>x_71</th>\n",
       "      <th>x_72</th>\n",
       "      <th>x_73</th>\n",
       "      <th>x_74</th>\n",
       "      <th>x_75</th>\n",
       "      <th>x_76</th>\n",
       "      <th>x_77</th>\n",
       "      <th>x_78</th>\n",
       "      <th>x_79</th>\n",
       "      <th>x_80</th>\n",
       "      <th>x_81</th>\n",
       "      <th>x_82</th>\n",
       "      <th>x_83</th>\n",
       "      <th>x_84</th>\n",
       "      <th>x_85</th>\n",
       "      <th>x_86</th>\n",
       "      <th>x_87</th>\n",
       "      <th>x_88</th>\n",
       "      <th>x_89</th>\n",
       "      <th>x_90</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_100</th>\n",
       "      <th>x_101</th>\n",
       "      <th>x_102</th>\n",
       "      <th>x_103</th>\n",
       "      <th>x_104</th>\n",
       "      <th>x_105</th>\n",
       "      <th>x_106</th>\n",
       "      <th>x_107</th>\n",
       "      <th>x_108</th>\n",
       "      <th>x_109</th>\n",
       "      <th>x_110</th>\n",
       "      <th>x_111</th>\n",
       "      <th>x_112</th>\n",
       "      <th>x_113</th>\n",
       "      <th>x_114</th>\n",
       "      <th>x_115</th>\n",
       "      <th>x_116</th>\n",
       "      <th>x_117</th>\n",
       "      <th>x_118</th>\n",
       "      <th>x_119</th>\n",
       "      <th>x_120</th>\n",
       "      <th>x_121</th>\n",
       "      <th>x_122</th>\n",
       "      <th>x_123</th>\n",
       "      <th>x_124</th>\n",
       "      <th>x_125</th>\n",
       "      <th>x_126</th>\n",
       "      <th>x_127</th>\n",
       "      <th>x_128</th>\n",
       "      <th>x_129</th>\n",
       "      <th>x_130</th>\n",
       "      <th>x_131</th>\n",
       "      <th>x_132</th>\n",
       "      <th>x_133</th>\n",
       "      <th>x_134</th>\n",
       "      <th>x_135</th>\n",
       "      <th>x_136</th>\n",
       "      <th>x_137</th>\n",
       "      <th>x_138</th>\n",
       "      <th>x_139</th>\n",
       "      <th>x_140</th>\n",
       "      <th>x_141</th>\n",
       "      <th>x_142</th>\n",
       "      <th>x_143</th>\n",
       "      <th>x_144</th>\n",
       "      <th>x_145</th>\n",
       "      <th>x_146</th>\n",
       "      <th>x_147</th>\n",
       "      <th>x_148</th>\n",
       "      <th>x_149</th>\n",
       "      <th>x_150</th>\n",
       "      <th>x_151</th>\n",
       "      <th>x_152</th>\n",
       "      <th>x_153</th>\n",
       "      <th>x_154</th>\n",
       "      <th>x_155</th>\n",
       "      <th>x_156</th>\n",
       "      <th>x_157</th>\n",
       "      <th>x_158</th>\n",
       "      <th>x_159</th>\n",
       "      <th>x_160</th>\n",
       "      <th>x_161</th>\n",
       "      <th>x_162</th>\n",
       "      <th>x_163</th>\n",
       "      <th>x_164</th>\n",
       "      <th>x_165</th>\n",
       "      <th>x_166</th>\n",
       "      <th>x_167</th>\n",
       "      <th>x_168</th>\n",
       "      <th>x_169</th>\n",
       "      <th>x_170</th>\n",
       "      <th>x_171</th>\n",
       "      <th>x_172</th>\n",
       "      <th>x_173</th>\n",
       "      <th>x_174</th>\n",
       "      <th>x_175</th>\n",
       "      <th>x_176</th>\n",
       "      <th>x_177</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956916</td>\n",
       "      <td>0.902494</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.709751</td>\n",
       "      <td>0.557823</td>\n",
       "      <td>0.321995</td>\n",
       "      <td>0.192744</td>\n",
       "      <td>0.147392</td>\n",
       "      <td>0.129252</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.092971</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.00907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.092971</td>\n",
       "      <td>0.113379</td>\n",
       "      <td>0.160998</td>\n",
       "      <td>0.185941</td>\n",
       "      <td>0.208617</td>\n",
       "      <td>0.219955</td>\n",
       "      <td>0.240363</td>\n",
       "      <td>0.231293</td>\n",
       "      <td>0.226757</td>\n",
       "      <td>0.231293</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.235828</td>\n",
       "      <td>0.235828</td>\n",
       "      <td>0.24263</td>\n",
       "      <td>0.249433</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.256236</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.276644</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.292517</td>\n",
       "      <td>0.303855</td>\n",
       "      <td>0.321995</td>\n",
       "      <td>0.337868</td>\n",
       "      <td>0.337868</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.319728</td>\n",
       "      <td>0.297052</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.371882</td>\n",
       "      <td>0.639456</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.29932</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.278912</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.251701</td>\n",
       "      <td>0.256236</td>\n",
       "      <td>0.247166</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2  x_3       x_4       x_5       x_6       x_7       x_8  \\\n",
       "0  0.904762  0.993197  1.0  0.956916  0.902494  0.857143  0.802721  0.777778   \n",
       "\n",
       "        x_9      x_10      x_11      x_12      x_13      x_14      x_15  \\\n",
       "0  0.709751  0.557823  0.321995  0.192744  0.147392  0.129252  0.099773   \n",
       "\n",
       "       x_16      x_17      x_18      x_19      x_20      x_21      x_22  \\\n",
       "0  0.092971  0.068027  0.068027  0.061224  0.040816  0.034014  0.027211   \n",
       "\n",
       "       x_23     x_24  x_25      x_26  x_27      x_28      x_29      x_30  \\\n",
       "0  0.013605  0.00907   0.0  0.006803   0.0  0.011338  0.015873  0.031746   \n",
       "\n",
       "       x_31      x_32      x_33      x_34      x_35      x_36      x_37  \\\n",
       "0  0.054422  0.092971  0.113379  0.160998  0.185941  0.208617  0.219955   \n",
       "\n",
       "       x_38      x_39      x_40      x_41      x_42      x_43      x_44  \\\n",
       "0  0.240363  0.231293  0.226757  0.231293  0.238095  0.235828  0.235828   \n",
       "\n",
       "      x_45      x_46      x_47      x_48      x_49      x_50      x_51  \\\n",
       "0  0.24263  0.249433  0.253968  0.258503  0.258503  0.256236  0.253968   \n",
       "\n",
       "       x_52      x_53      x_54      x_55      x_56      x_57      x_58  \\\n",
       "0  0.265306  0.263039  0.272109  0.265306  0.260771  0.263039  0.267574   \n",
       "\n",
       "       x_59      x_60      x_61      x_62      x_63      x_64      x_65  \\\n",
       "0  0.267574  0.274376  0.258503  0.265306  0.263039  0.267574  0.272109   \n",
       "\n",
       "       x_66      x_67      x_68      x_69      x_70      x_71      x_72  \\\n",
       "0  0.263039  0.260771  0.274376  0.269841  0.274376  0.276644  0.269841   \n",
       "\n",
       "       x_73      x_74      x_75      x_76      x_77      x_78      x_79  \\\n",
       "0  0.267574  0.274376  0.292517  0.303855  0.321995  0.337868  0.337868   \n",
       "\n",
       "       x_80      x_81      x_82      x_83      x_84      x_85      x_86  \\\n",
       "0  0.340136  0.319728  0.297052  0.285714  0.269841  0.269841  0.274376   \n",
       "\n",
       "       x_87      x_88      x_89      x_90      x_91      x_92      x_93  \\\n",
       "0  0.269841  0.274376  0.267574  0.260771  0.371882  0.639456  0.959184   \n",
       "\n",
       "       x_94      x_95     x_96      x_97      x_98      x_99     x_100  \\\n",
       "0  0.807256  0.444444  0.29932  0.272109  0.278912  0.253968  0.258503   \n",
       "\n",
       "      x_101     x_102     x_103     x_104     x_105     x_106  x_107  x_108  \\\n",
       "0  0.251701  0.256236  0.247166  0.265306  0.265306  0.267574    0.0    0.0   \n",
       "\n",
       "   x_109  x_110  x_111  x_112  x_113  x_114  x_115  x_116  x_117  x_118  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_119  x_120  x_121  x_122  x_123  x_124  x_125  x_126  x_127  x_128  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_129  x_130  x_131  x_132  x_133  x_134  x_135  x_136  x_137  x_138  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_139  x_140  x_141  x_142  x_143  x_144  x_145  x_146  x_147  x_148  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_149  x_150  x_151  x_152  x_153  x_154  x_155  x_156  x_157  x_158  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_159  x_160  x_161  x_162  x_163  x_164  x_165  x_166  x_167  x_168  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_169  x_170  x_171  x_172  x_173  x_174  x_175  x_176  x_177  x_178  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_179  x_180  x_181  x_182  x_183  x_184  x_185  x_186  x_187  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_patient = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_new_patient.csv')\n",
    "new_patient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Columns: 187 entries, x_1 to x_187\n",
      "dtypes: float64(187)\n",
      "memory usage: 1.6 KB\n"
     ]
    }
   ],
   "source": [
    "new_patient.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Predict the target for the new patient 'new_patient'\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X, y)\n",
    "new_patient['target'] = model.predict(new_patient)\n",
    "\n",
    "prediction = \"at risk\" if new_patient['target'][0] == 1 else \"healthy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª **Check your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/tanushrinayak/.pyenv/versions/3.10.6/envs/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/tanushrinayak/code/tanushrin/05-ML/03-Performance-metrics/data-electrocardiograms/tests\n",
      "plugins: asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_prediction.py::TestPrediction::test_prediction_at_risk \u001b[32mPASSED\u001b[0m\u001b[32m       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/prediction.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed prediction step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('prediction',\n",
    "                         prediction = prediction)\n",
    "result.write()\n",
    "print(result.check())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ Congratulations!\n",
    "\n",
    "ðŸ’¾ Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "ðŸš€ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
